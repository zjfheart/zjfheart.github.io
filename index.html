<html>

<head>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="stylesheet" type="text/css" href="style.css" />
    <title>Jingfeng Zhang</title>
    <base href="https://zjfheart.github.io/index">
</head>

<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<h1 style="padding-left: 0.5em">Jingfeng Zhang</h1><hr>
<td id="layout-menu">
    <div class="menu-item"><a href="index.html" class="current">Home</a></div>
    <div class="menu-item"><a href="#news">News</a></div>
    <div class="menu-item"><a href="#research">Research</a></div>
    <div class="menu-item"><a href="#publications">Publications</a></div>
	<div class="menu-item"><a href="#service">Professional Service</a></div>
    <div class="menu-item"><a href="#funding">Funding</a></div>
</td>

<td id="layout-content">

    <h1 style="margin-top: 0em">Home</h1><br>
  <!--  <p>[ <a href="#news">News</a>,
        <a href="#interest">Research Interests</a>,
        <a href="#job">Job Experience</a>,
        <a href="#edu">Education</a> ]</p>-->

    <table class="imgtable"><tr valign="center">
        <td><img src="jzhangv.jpg" width = '240', height='300' alt="Jingfeng Zhang" /></td>
        <td align="left">
            <p><span style="font-size: 110%"><b>Jingfeng Zhang (张 景锋)</b></span></p>
            <p>
                Jan. 2021 - Present, Postdoctoral researcher @ <a href="https://aip.riken.jp/labs/generic_tech/imperfect_inf_learn/" target="_blank">Imperfect Information Learning Team</a><br>
                <a href="http://www.riken.jp/en/" target="_blank">RIKEN</a>
                <a href="https://aip.riken.jp/" target="_blank">Center for Advanced Intelligence Project</a> <br>
                Supervised by <a href='http://www.ms.k.u-tokyo.ac.jp/sugi/' target="_blank">Prof. Masashi Sugiyama</a>
			</p>
			<p>
                Aug. 2016 - Dec. 2020, <a href="https://www.comp.nus.edu.sg/programmes/pg/phdcs/alum/" target="_blank">Doctor of Philosophy</a> @ <a href="https://www.comp.nus.edu.sg" target="_blank">School of Computing</a><br>
                <a href="https://www.nus.edu.sg" target="_blank"> National University of Singapore</a> <br>
                Supervised by <a href='https://www.comp.nus.edu.sg/cs/bio/mohan/' target="_blank">Prof. Mohan Kankanhalli</a>
            </p>
            <p>
                Sept. 2012 - Jul. 2016, Bachelor of Engineering @ <a href="https://www.tsxt.sdu.edu.cn" target="_blank">Taishan College</a><br>
                <a href="https://www.sdu.edu.cn" target="_blank"> Shandong University</a> <br>
            </p>

            <p>
                <a href="http://scholar.google.com/citations?user=NS0P1FkAAAAJ&hl=en" target="_blank">[Google Scholar]</a>
                <a href="https://github.com/zjfheart" target="_blank">[Github]</a><br>
				<!-- <a href="http://csrankings.org/#/fromyear/2019/toyear/2020/index?ai&mlmining&world" target="_blank">[CSRankings]</a> -->
				E-mail: jingfeng.zhang@riken.jp / jingfeng.zhang9660@gmail.com<br>
                <p><font color="#FF0000"><a href="https://trustmlresearch.github.io" target="_blank">TrustML YSS</a> is inviting speakers across the globe, contact me if you are interested!</p>
            </p>
        </td>
    </tr></table>

    <!-- <p><font color="#FF0000">I am seeking for <b>Assistant Professor</b> or <b>Research Scientist</b>!</font></p> -->
 
 <div>
        <h2 id='news'><hr><a name="news"></a>News</h2>
        <ul>
            <li><p>September 2022: Two papers get accepted at NeurIPS 2022!
            <li><p>September 2022: I have given invited talks at Ludwig Maximilian University of Munich, the Technical University of Munich, and the Technical University of Berlin.
            <li><p>September 2022: I am invited to serve as a reviewer for AISTAT 2023.
            <li><p>September 2022: I have served on the Ph.D. dissertation defense committee at the University of Luxembourg. Congratulations to Dr. Salah Ghamizi for passing his Ph.D. defense.
            <li><p>August 2022: I will serve as reviewer for AAAI 2023 and ICLR 2023.
            <li><p>August 2022: I have given an invited talk at Visual Informatics Group in University of Texas at Austin.
            <li><p>August 2022: I have given an invited talk at CCF Jinan Trusted Artificial Intelligence International Academic Forum. [<a href="https://www.ccf.org.cn/Chapters/Local_Activities/Chapter_News/2022-08-11/767420.shtml", target="_blank">link</a>]
            <li><p>July 2022: The research proposal "Evaluating and Enhancing the Reliability of Semi-Supervised Learning" has been accepted at RIKEN-Kyushu Univ Science & Technology Hub Collaborative Research Program FY2022, and I serve as the co-leader.
            <li><p>June 2022: I am invited to join the thesis defense Jury and will visit the University of Luxembourg in September.
            <li><p>June 2022: I gave an online talk at the University of Manchester titled "Pioneer Studies on Adversarial Robustness of Deep Image Denoisers and Non-parametric Two-Sample Tests."
            <li><p>May 2022: I am invited to give an online talk at the <a href="https://www.epfl.ch/research/domains/cis/center-for-intelligent-systems-cis/events/riken/", target="_blank"> EPFL CIS – RIKEN AIP</a> workshop in September. [<a href='https://aip.riken.jp/events/141125/', target="_blank">AIP Web</a>] [<a href='https://www.epfl.ch/research/domains/cis/riken-epfl-workshop-2022/', target="_blank">EPFL-CIS Web</a>]
            <li><p>May 2022: I am invited to give an onsite talk at Infomation-Based Induction Sciences and Machine Learning (<a href="https://www.ieice.org/ken/program/index.php?mode=program&tgs_regid=573b590be2db461c85c4bd7ff68a579260bbb957d0bdc6ade634542b9d28dfa8&tgid=IEICE-IBISML&layout=&lang=eng", target="_blank">IBISML</a>) titled "Evaluating and Enhancing Reliabilities of AI-Powered Tools." </p></li>
            <li><p>May 2022: I will serve as reviewer for Conference on Neural Information Processing Systems (NeurIPS 2022). </p></li>
            <li><p>April 2022: I gave an online talk at Shanghai Jiao Tong University titled "Adversarial Robustness from Basic Science to some Applications." </p></li>
            <li><p>March 2022: I am invited to serve as a reviewer for European Conference on Computer Vision (ECCV 2022). </p></li>
            <li><p>March 2022: My research proposal "Adversarial robustness meets imperfect training set" has been accepted in the Grants-in-Aid for Scientific Research-KAKENHI, Early-Career Scientists, JSPS. </p></li>
            <li><p>March 2022: I am honored to receive the <a href="https://aip.riken.jp/news/fy2021_riken_ohbu_award/", target="_blank">RIKEN Ohbu award</a> (research incentive award). </p></li>
            <li><p>March 2022: I will give an invited talk at <a href="https://aaai.org/Conferences/AAAI-22/", target="_blank">AAAI22</a>' Workshop on <a href="https://advml-workshop.github.io/aaai2022/", target="_blank">Adversarial Machine Learning and Beyond</a>. [<a href="https://www.youtube.com/watch?v=3Z8bUgn41Fk", target="_blank">Video</a>] </p></li>
            <li><p>Feburary 2022: I am invited to serve as a reviewer for Transactions on Machine Learning Research (TMLR). </p></li>
            <li><p>Feburary 2022: I will be serving as a reviewer for ACM SIGKDD 2022. </p></li>
        </ul>
        See more news <a href="https://zjfheart.github.io/news.html" target="_blank">here</a>.
 </div>

<div>
        <h2 id='research'><hr><a name="research"></a>Research</h2>
<ul> I am machine learning researcher with the research interest in trustworthy machine learning. My long-term goal is to develop safe, trustworthy, reliable, and extensible machine learning (ML) technologies. Researching adversarial training (AT) is the first step towards achieving my long-term goal. </ul>

<ul>[Background] There is a widely observed fact that the outputs of naturally occurring systems are mostly smooth with respect to the inputs, and so the ML systems should follow this fact. However, many existing ML systems neglect this fact, which causes the trustworthy issues. One example is the small adversarial noise failing the ML model’s predictions, even if the model is trained via standard isotropic smoothing techniques such as the random noise or the random data augmentation. Another example is the crafted noises in the training set manipulating the ML’s learning process, which outputs an untrusted (poisoned) model. <br><br>
    
    What is AT? AT is a trendy robust learning algorithm. Unlike standard training (ST) that directly learns from the natural data, AT learns from the adversarial data within a bounded distance of their natural counterparts. At each training epoch, the adversarial data are generated towards the direction that reduces the model’s probability of correct classifications. AT aims to achieve two purposes: (1) correctly classify the data (the same as ST) and (2) make the decision boundary thick so that no data lie nearby the decision boundary. <br><br>
    
    My research is to develop the effective robust learning algorithms, discover the new knowledge, apply the developed techniques to enhance the reliability, and further evaluate the vulnerabilities of the learning algorithms.
</ul>

<ul><li>
    To <b>defend against the adversarial attacks</b>, I develop the effective learning strategies, explore the robust network structures, detect the adversarial examples. <br>
    [Learning strategies]<br>
    <a href="https://arxiv.org/abs/2002.11242" target="_blank">Attacks which do not kill training make adversarial learning stronger</a> in 2020. (<font color="#FF0000">ICML 2020 accept</font>) <br>
    <a href="https://openreview.net/forum?id=iAX0l6Cz8ub" target="_blank">Geometry-aware instance-reweighted adversarial training</a> in 2020. (<font color="#FF0000">ICLR 2021 accept as oral</font>) <br>
    <a href="https://openreview.net/forum?id=zlQXV7xtZs" target="_blank">NoiLin: Improving adversarial training and correcting stereotype of noisy labels</a> in 2021. (<font color="#FF0000">TMLR 2022 accept</font>)<br>
    Synergy-of-Experts: Collaborate to improve adversarial robustness in 2021. (<font color="#FF0000">NeurIPS 2022 accept</font>) <br>
    <a href="https://www.computer.org/csdl/journal/tq/5555/01/09754227/1CpdbPTwCxq" target="_blank">Decision boundary-aware data augmentation for adversarial training</a> in 2021. (<font color="#FF0000">IEEE TDSC 2022 accept</font>) <br>
    <a href="https://openreview.net/forum?id=u6TRGdzhfip" target="_blank"> Reliable adversarial distillation with unreliable teachers</a> in 2021. (<font color="#FF0000">ICLR 2022 accept</font>) <br>
    Adversarial training with complementary labels: On the benefits of gradually informative attacks in 2022. (<font color="#FF0000">NeurIPS 2022 accept</font>) <br>
    ATTA: Improving adversarial training with task augmentation in 2022. (<font color="#00B900">under review</font>) <br>
    <br>
    [Robust network structures] <br>
    <a href="https://arxiv.org/pdf/1902.10887.pdf" target="_blank">Towards robust ResNet: A small step but a giant leap</a> in 2019. (<font color="#FF0000">IJCAI 2019 accept</font>) <br>
    <a href="https://arxiv.org/abs/2102.01886" target="_blank">Learning diverse-structured networks for adversarial robustness</a> in 2021. (<font color="#FF0000">ICML 2021 accept</font>) <br>
    <a href="https://arxiv.org/abs/2102.05311" target="_blank">CIFS: Improving adversarial robustness of CNNs via channel-wise importance-based feature selection</a> in 2021. (<font color="#FF0000">ICML 2021 accept</font>) <br>
    <br>
    [Adversary detections] <br>
    <a href="https://arxiv.org/abs/2010.11415", target="_blank">Maximum mean discrepancy test is aware of adversarial attacks</a> in 2021. (<font color="#FF0000">ICML 2021 accept</font>) <br>
</li>
</ul>


<ul><li> To <b>discover the new knowledge</b>, I find AT has the <b>smoothing effect</b> against the imperfections of the training sets, such as noisy labels or backdoors.<br>
    <a href="https://arxiv.org/abs/2102.03482",target="_blank">Understanding the interaction of adversarial training with noisy labels</a> in 2021. (<font color="#00B900">under review</font>)<br>
    <a href="https://arxiv.org/abs/2202.10627",target="_blank">On the effective adversarial training against backdoor attacks</a> in 2022. (<font color="#00B900">under review</font>)</li>
</ul>
<ul>
    <li> To <b>apply the developed techniques</b>, the AT's techniques can <b>evaluate/enhance the reliabilities of some tools</b>, such as image denoiser and non-parametric two sample tests.<br>
    <a href="https://arxiv.org/abs/2201.04397",target="_blank">Towards adversarially robust image denoising</a> in 2022. (<font color="#FF0000">IJCAI2022 accept! </font>) <br>
    <a href="https://arxiv.org/abs/2202.03077",target="_blank">Adversarial attacks and defenses for non-parametric two sample tests</a> in 2022. (<font color="#FF0000">ICML2022 accept! </font>)
    </li>
</ul>

<ul>
    <li> To <b>evaluate the vulnerabilities of the learning algorithms</b>, we develop the training-phase attacks.<br>
        Know the enemy and know yourself: Towards poisoning attacks against adversarial training in 2022. (<font color="#00B900">under review</font>)<br>
        Model and method: Training-time attack for cooperative multi-agent reinforcement learning in 2022. (<font color="#00B900">under review</font>) <br>
    </li>
</ul>

<ul><li>
 Besides, I am also interested in the <b>privacy protection</b>. <br>
Turn poisoning into a strength: preventing unauthorized exploitation by poisoning voice in 2022. (<font color="#00B900">under review</font>) <br>
Bilateral dependency optimization: defending against model-inversion attacks in 2021. (<font color="#FF0000">KDD2022 accept!</font>) <br>
</li></ul>

</div>


    
    <div>
        <h2 id='publications'><hr><a name="publications"></a>Publications</h2> (* indicates equal contributions)
        <ul>
            <li><p>Synergy-of-Experts: Collaborate to Improve Adversarial Robustness.<br>
                S. Cui*, <b>J. Zhang*</b>, J. Liang, B. Han, M. Sugiyama, C. Zhang.<br>
             <i>36th Annual Conference on Neural Information Processing Systems (NeurIPS 2022)</i>, [PDF] [Code] [Poster].</p></li>
            
            
            <li><p>Adversarial Training with Complementary Labels: On the Benefit of Gradually Informative Attacks.<br>
                J. Zhou*, J. Zhou*, <b>J. Zhang</b>, T. Liu, G. Niu, B. Han, M. Sugiyama.<br>
             <i>36th Annual Conference on Neural Information Processing Systems (NeurIPS 2022)</i>, [PDF] [Code] [Poster].</p></li>
            
            <li><p>NoiLin: Improving Adversarial Training and Correcting Stereotype of Noisy Labels.<br>
                <b>J. Zhang*</b>, X. Xu*, B. Han, T. Liu, N. Gang, L. Cui, M. Sugiyama.<br>
             <i><a href="https://jmlr.org/tmlr/", target="_blank">Transactions on Machine Learning Research</a> (TMLR 2022)</i>, [<a href="https://openreview.net/forum?id=zlQXV7xtZs" target="_blank">PDF</a>] [<a href="https://github.com/zjfheart/NoiLIn.git" target="_blank">Code</a>].</p></li>
            
            <li><p>Bilateral Dependency Optimization: Defending Against Model-inversion Attacks.<br>
                X. Peng*, F. Liu*, <b>J. Zhang</b>, L. Lan, J. Ye, T. Liu, B. Han.<br>
             <i>28th ACM SIGKDD conference on Knowledge Discovery and Data Mining (KDD 2022)</i>, [<a href="https://dl.acm.org/doi/abs/10.1145/3534678.3539376" target="_blank">PDF</a>] [<a href="https://github.com/xpeng9719/Defend_MI" target="_blank">Code</a>] [Poster].</p></li>
            
            <li><p>Adversarial Attacks and Defense For Non-parametric Two Sample Tests.<br>
             X. Xu*, <b>J. Zhang*</b>, F. Liu, M. Sugiyama, and M. Kankanhalli.<br>
             <i>The 39th International Conference on Machine Learning (ICML 2022)</i>, [<a href="https://arxiv.org/abs/2202.03077" target="_blank">PDF</a>] [<a href="https://github.com/GodXuxilie/Robust-TST.git" target="_blank">Code</a>] [Poster].</p></li>
            
            <li><p>Towards Adversarially Robust Image Denoising.<br>
             H. Yan, <b>J. Zhang</b>, J. Feng, M. Sugiyama, and V. Y. F. Tan.<br>
             <i>The 31st International Joint Conference on Artificial Intelligence (IJCAI 2022)</i>, [<a href="https://arxiv.org/abs/2201.04397" target="_blank">PDF</a>] [<a href="https://github.com/HanshuYAN/ObsAtk" target="_blank">Code</a>] [Poster].</p></li>
            
            <li><p>Decision Boundary-aware Data Augmentation for Adversarial Training.<br>
            C. Chen*, <b>J. Zhang</b>*, X. Xu, L. Lyu, C. Chen, T. Hu, G. Chen.<br>
            <i>IEEE Transactions on Dependable and Secure Computing (IEEE TDSC 2022)</i>, [<a href="https://www.computer.org/csdl/journal/tq/5555/01/09754227/1CpdbPTwCxq" target="_blank">PDF</a>] [<a href="#publications">Code</a>].</p></li>
            
            <li><p>Reliable Adversarial Distillation with Unreliable Teachers.<br>
            J. Zhu, J. Yao, B. Han, <b>J. Zhang</b>, T. Liu, G. Niu, J. Zhou, J. Xu, H. Yang.<br>
            In Proceedings of <i>10th International Conference on Learning Representations (ICLR 2022)</i>, [<a href="https://openreview.net/forum?id=u6TRGdzhfip" target="_blank">PDF</a>] [<a href="#publications">Code</a>] [<a href="#publications", target="_blank">Poster</a>].</p></li>

           <li><p>CIFS: Improving Adversarial Robustness of CNNs via Channel-wise Importance-based Feature Selection.<br>
           H. Yan, <b>J. Zhang</b>, G. Niu, J. Feng, V. Y. F. Tan, M. Sugiyama.<br>
           In Proceedings of <i>38th International Conference on Machine Learning (ICML 2021)</i>, [<a href="http://proceedings.mlr.press/v139/yan21e.html" target="_blank">PDF</a>] [<a href="codes/CIFS_sharing.zip" download>Code</a>] [<a href="https://icml.cc/virtual/2021/spotlight/10648", target="_blank">Poster</a>].</p></li>  


          <li><p>Maximum Mean Discrepancy is Aware of Adversarial Attacks.<br>
           R. Gao*, F. Liu*, <b>J. Zhang</b>*, B. Han, T. Liu, G. Niu, and M. Sugiyama.<br>
           In Proceedings of <i>38th International Conference on Machine Learning (ICML 2021)</i>, [<a href="http://proceedings.mlr.press/v139/gao21b.html" target="_blank">PDF</a>] [<a href="https://github.com/Sjtubrian/SAMMD", target="_blank"> Code</a>] [<a href="https://icml.cc/virtual/2021/spotlight/10684", target="_blank">Poster</a>].</p></li>  

          <li><p>Learning Diverse-Structured Networks for Adversarial Robustness.<br>
           X. Du*, <b>J. Zhang</b>*, B. Han, T. Liu, Y. Rong, G. Niu, J. Huang and M. Sugiyama.<br>
           In Proceedings of <i>38th International Conference on Machine Learning (ICML 2021)</i>, [<a href="http://proceedings.mlr.press/v139/du21f.html" target="_blank">PDF</a>] [<a href="https://github.com/d12306/dsnet", target="_blank"> Code</a>] [<a href="https://icml.cc/virtual/2021/spotlight/10510", target="_blank">Poster</a>].</p></li>  

          <li><p>Geometry-aware Instance-reweighted Adversarial Training.<br>
           <b>J. Zhang</b>, J. Zhu, G. Niu, B. Han, M. Sugiyama, and M. Kankanhalli.<br>
           In Proceedings of <i>9th International Conference on Learning Representations (ICLR 2021, Oral)</i>, [<a href="https://openreview.net/pdf?id=iAX0l6Cz8ub" target="_blank">PDF</a>] [<a href="https://github.com/zjfheart/Geometry-aware-Instance-reweighted-Adversarial-Training" target="_blank">Code</a>] [<a href="https://iclr.cc/virtual/2021/poster/2758" target="_blank">Poster</a>].</p></li> 
 
           <li><p> Attacks Which Do Not Kill Training Make Adversarial Learning Stronger.<br>
            <b>J. Zhang</b>*, X. Xu*, B. Han, G. Niu, L. Cui, M. Sugiyama, and M. Kankanhalli.<br>
           In Proceedings of <i>37th International Conference on Machine Learning (ICML 2020)</i>, [<a href="https://proceedings.mlr.press/v119/zhang20z/zhang20z.pdf" target="_blank">PDF</a>] [<a href="https://github.com/zjfheart/Friendly-Adversarial-Training" target="_blank">Code</a>] [<a href="https://icml.cc/virtual/2020/poster/5835" target="_blank">Poster</a>].</p></li>


		  <li><p>Towards Robust ResNet: A Small Step but A Giant Leap.<br>
           <b>J. Zhang</b>, B. Han, L. Wynter, B. Low, and M. Kankanhalli.<br>
           In Proceedings of <i>28th International Joint Conference on Artificial Intelligence (IJCAI 2019)</i>, [<a href="https://www.ijcai.org/proceedings/2019/0595.pdf" target="_blank">PDF</a>] [<a href="https://github.com/zjfheart/Robust-ResNet" target="_blank">Code</a>] [<a href="papers/robust_resnet_poster.pdf" target="_blank">Poster</a>].</p></li>
        </ul>
    </div>
	
    <div>
            <h2 id='service'><hr><a name="service"></a>Professional Service</h2>
            <ul>
                <p> <span style="font-size: 100%"> <strong>Organizer of workshops & seminars</strong> </p>
                <p> TrustML Young Scientist Seminars (<a href="https://trustmlresearch.github.io" target="_blank">TrustML YSS</a>)  [<a href="https://www.youtube.com/channel/UCipPccqvcfychKNOaYUokyQ" target="_blank">Video series</a>] </p>
                <p> ACML 2021 Workshop on <a href="https://wsl-workshop.github.io/acml21.html" target="_blank"> Weakly Supervised Representation Learning </a>
                </p>
            </ul>
            <ul>
               <p> <span style="font-size: 100%"> <strong>Reviewer for prestigious conferences</strong> </p>
               <p> ICLR'21-22, ICML'20-22, NeurIPS'21-22, CVPR'22, IJCAI'20-22, AAAI'22, ACM Multimedia'21, ACM SIGKDD'22, etc.</p>
            </ul>
            
            <ul>
               <p> <span style="font-size: 100%"> <strong>Reviewer for prestigious journals</strong> </p>
               <p> MLJ, TMLR, TNNLS, PR, Neural Networks, etc.</p>
            </ul>
            
            <ul>
            
            <p> <span style="font-size: 100%"> <strong>Invited lecturer</strong> </p>
               <p>2022 Spring Semester (S1 Term) @ <a href="https://www.i.u-tokyo.ac.jp/greeting_e.shtml" target="_blank">Graduate School of Information Science and Technology</a>, <a href="https://www.u-tokyo.ac.jp/en/index.html" target="_blank">The University of Tokyo</a>, <a href="https://www.i.u-tokyo.ac.jp/edu/proced/sche_sa_e.shtml" target="_blank">Special Topics in Mechano-Informatics II (4850-1022)</a>---Trustworthy machine learning [<a href="talks/slides/TrustML_Lecture.pdf">course slides</a>]<br/>
               </p>
            
            <p> <span style="font-size: 100%"> <strong>Teaching assistant</strong> </p>
               <p>2017/2018 Semester 2, BT5152 @ School of Computing, NUS, Decision Making Technologies <br/>
               2017/2018 Semester 2, CS3243 @ School of Computing, NUS, Introduction to Artificial Intelligence<br/>
               2016/2017 Semester 2, CS3243 @ School of Computing, NUS, Introduction to Artificial Intelligence</p>
            </ul>
            
            <ul> <p> <span style="font-size: 100%"> <strong>Research advisor</strong> </p>
                <p>
                (Students who closely work  or worked with me.) <br>
                [09/2020 - Present] Hanshu Yan PhD Student@NUS (with Dr. Vincent Tan)                          <br>
                [04/2019 - Present] Xilie Xu Undergrad@SDU → PhD Student@NUS (with Prof. Mohan Kankanhalli)  <br>
                [03/2020 - Present] Jianing Zhu Undergrad@SCU → PhD Student@BUHK (with Dr. Bo Han)          <br>
                
                [04/2021 - Present] Bo Song Master Student@SDU (with Prof. Lei Liu)                                 <br>
                [04/2021 - Present] Ting Zhou Master Student@SDU (with Prof. Lei Liu)                                  <br>
                [07/2020 – 3/2021] Xuefeng Du (now PhD Student@UW-Madison) RA@BUHK (with Dr. Bo Han)                        <br>
                [07/2020 – 3/2021] Ruize Gao (now PhD Student@NUS) RA@BUHK (with Dr. Bo Han)                               </p>
            </ul>
               
        
    </div>
    
    
    <div>
            <h2 id='funding'><hr><a name="funding"></a>Funding</h2>
            
    <ul>
        RIKEN-Kyushu Univ Science & Technology Hub Collaborative Research Program, Japan [FY2022]
    </ul>
    
    <ul>
        <a href="https://www.jsps.go.jp/english/e-grants/" target="_blank">JSPS Grants-in-Aid for Scientific Research (KAKENHI)</a>, Early-Career Scientists, Grant Number 22K17955, Japan [FY2022 - FY2023]
    </ul>
    <ul>
        <a href="https://www.jst.go.jp/kisoken/boshuu/teian/en/top/gaiyo.html" target="_blank">JST Strategic Basic Research Programs</a>, <a href="https://www.jst.go.jp/kisoken/act-x/en/about/index.html" target="_blank">ACT-X</a>, Grant Number JPMJAX21AF, Japan [<a href="https://www.jst.go.jp/kisoken/act-x/application/2021/210921/210921act-x.pdf" target="_blank">Annoucement</a>] [FY2021 - FY2023]
    </ul>
    </div>
    
    
	<div>
        <h2><hr><a name="biography"></a>Brief Biography</h2>
        <ul>
           Jingfeng Zhang is currently a postdoctoral researcher at RIKEN-AIP in Tokyo, Japan.
           <br/> <br/>
           
         During his undergraduate period, he studied at <a href="https://www.cam.ac.uk" target="_blank"> University of Cambridge</a> for two months and <a href="https://www.ucla.edu" target="_blank"> University of California, Los Angeles</a> for three months. Finally, he went to Singapore for his Ph.D. study; he had a happy life there with many lovely friends and supportive mentors. He likes Malaysian durian! <br/> <br/>

          During his Ph.D. study, he had two valuable internship experiences. In 2018, he was interning at <a href="https://www.ibm.com/sg-en", target="_blank">IBM Singapore</a> advised by <a href="https://scholar.google.com/citations?hl=en&user=l-6wx2sAAAAJ&view_op=list_works&sortby=pubdate", target="_blank">Laura Wynter</a>, working on the "robust ResNet" project. In 2019, he was interning at the Imperfect Information Learning Team at RIKEN-AIP advised by <a href="https://bhanml.github.io" target="_blank">Bo Han</a>, <a href="https://niug1984.github.io/" target="_blank">Gang Niu</a>, and <a href="http://www.ms.k.u-tokyo.ac.jp/sugi/" target="_blank">Masashi Sugiyama</a>, working on the "adversarial robustness" project.
		   </p></li>
        </ul>
    </div>

<!-- <script src="//t1.extreme-dm.com/f.js" id="eXF-bhan-0" async defer></script> -->
<!--Theme from <a href="https://www.cc.gatech.edu/~lsong/" target="_blank">Prof. Le Song</a>-->
</td>
</tr>
</table>
</body>

</html>
